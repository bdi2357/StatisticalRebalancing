{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPguUXI96VG4VTObZKCRG6H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bdi2357/StatisticalRebalancing/blob/main/Rebalancing_tests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_LYBEHWurya",
        "outputId": "db2dc75a-2737-48f8-aca2-ab8655ac1fcd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv archive\\ \\(13\\).zip archive.zip"
      ],
      "metadata": {
        "id": "wUcOBAq8uvuQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
        "\n",
        "\n",
        "# Load the dataset into a pandas DataFrame\n",
        "df = pd.read_csv('creditcard.csv')\n",
        "print(df.head())\n",
        "\n",
        "# Check for NaN values in the target variable\n",
        "print(df['Class'].isna().sum())\n",
        "\n",
        "# Drop rows where target variable is NaN\n",
        "df = df.dropna(subset=['Class'])\n",
        "\n",
        "# Prepare the dataset for comparison\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Define the resampling techniques\n",
        "resampling_techniques = {\n",
        "    'Original': (X_train, y_train),\n",
        "    'SMOTE': SMOTE(random_state=42).fit_resample(X_train, y_train),\n",
        "    'ADASYN': ADASYN(random_state=42).fit_resample(X_train, y_train),\n",
        "    'RandomOverSampler': RandomOverSampler(random_state=42).fit_resample(X_train, y_train)\n",
        "}\n",
        "\n",
        "# Define classifiers to test\n",
        "classifiers = {\n",
        "    'RandomForest': RandomForestClassifier(),\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000)\n",
        "}\n",
        "\n",
        "# Define metrics for evaluation\n",
        "metrics = [f1_score, precision_score, recall_score, roc_auc_score]\n",
        "\n",
        "# Store results\n",
        "results = pd.DataFrame(columns=['Dataset', 'Classifier'] + [metric.__name__ for metric in metrics])\n",
        "\n",
        "# Evaluate each resampled dataset with each classifier\n",
        "for resampling_name, (X_res, y_res) in resampling_techniques.items():\n",
        "    for clf_name, clf in classifiers.items():\n",
        "        clf.fit(X_res, y_res)\n",
        "        predictions = clf.predict(X_test)\n",
        "        probabilities = clf.predict_proba(X_test)[:, 1]  # For ROC AUC\n",
        "\n",
        "        # Evaluate with each metric\n",
        "        precision = precision_score(y_test, predictions, zero_division=1)\n",
        "        recall = recall_score(y_test, predictions)\n",
        "        f1 = f1_score(y_test, predictions, zero_division=1)\n",
        "        roc_auc = roc_auc_score(y_test, probabilities)\n",
        "\n",
        "        # Append to results DataFrame\n",
        "        row = pd.DataFrame([[resampling_name, clf_name, precision, recall, f1, roc_auc]], columns=results.columns)\n",
        "        results = pd.concat([results, row], ignore_index=True)\n",
        "\n",
        "# Calculate an overall score for ranking (optional)\n",
        "results['Overall Score'] = results[[metric.__name__ for metric in metrics]].mean(axis=1)\n",
        "\n",
        "# Sort results for ranking\n",
        "ranked_results = results.sort_values(by='Overall Score', ascending=False)\n",
        "\n",
        "# Display the ranked table\n",
        "print(ranked_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOftKKUSuqsu",
        "outputId": "9d4c7d8b-d9a3-4a0f-9077-927444cab821"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
            "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
            "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
            "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
            "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
            "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
            "\n",
            "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
            "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
            "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
            "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
            "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
            "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
            "\n",
            "        V26       V27       V28  Amount  Class  \n",
            "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
            "1  0.125895 -0.008983  0.014724    2.69      0  \n",
            "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
            "3 -0.221929  0.062723  0.061458  123.50      0  \n",
            "4  0.502292  0.219422  0.215153   69.99      0  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "0\n",
            "             Dataset          Classifier  f1_score  precision_score  \\\n",
            "0           Original        RandomForest  0.965217         0.750000   \n",
            "2              SMOTE        RandomForest  0.880597         0.797297   \n",
            "6  RandomOverSampler        RandomForest  0.964286         0.729730   \n",
            "4             ADASYN        RandomForest  0.847826         0.790541   \n",
            "1           Original  LogisticRegression  0.830189         0.594595   \n",
            "5             ADASYN  LogisticRegression  0.079110         0.864865   \n",
            "3              SMOTE  LogisticRegression  0.069437         0.858108   \n",
            "7  RandomOverSampler  LogisticRegression  0.045518         0.878378   \n",
            "\n",
            "   recall_score  roc_auc_score  Overall Score  \n",
            "0      0.844106       0.930616       0.872485  \n",
            "2      0.836879       0.950384       0.866290  \n",
            "6      0.830769       0.930367       0.863788  \n",
            "4      0.818182       0.959402       0.853988  \n",
            "1      0.692913       0.923833       0.760382  \n",
            "5      0.144960       0.954700       0.510909  \n",
            "3      0.128477       0.944821       0.500211  \n",
            "7      0.086551       0.960256       0.492676  \n",
            "CPU times: user 21min 28s, sys: 9.87 s, total: 21min 38s\n",
            "Wall time: 21min 35s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "osRHcXIBuQJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from zipfile import ZipFile\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
        "\n",
        "\n",
        "# Load the dataset into a pandas DataFrame\n",
        "df = pd.read_csv('diabetes.csv')\n",
        "print(df.shape)\n",
        "print(df.head())\n",
        "\n",
        "# Check for NaN values in the target variable\n",
        "print(df['Outcome'].isna().sum())\n",
        "\n",
        "# Drop rows where target variable is NaN\n",
        "df = df.dropna(subset=['Outcome'])\n",
        "\n",
        "# Prepare the dataset for comparison\n",
        "X = df.drop('Outcome', axis=1)\n",
        "y = df['Outcome']\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Define the resampling techniques\n",
        "resampling_techniques = {\n",
        "    'Original': (X_train, y_train),\n",
        "    'SMOTE': SMOTE(random_state=42).fit_resample(X_train, y_train),\n",
        "    'ADASYN': ADASYN(random_state=42).fit_resample(X_train, y_train),\n",
        "    'RandomOverSampler': RandomOverSampler(random_state=42).fit_resample(X_train, y_train)\n",
        "}\n",
        "\n",
        "# Define classifiers to test\n",
        "classifiers = {\n",
        "    'RandomForest': RandomForestClassifier(),\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000)\n",
        "}\n",
        "\n",
        "# Define metrics for evaluation\n",
        "metrics = [f1_score, precision_score, recall_score, roc_auc_score]\n",
        "\n",
        "# Store results\n",
        "results = pd.DataFrame(columns=['Dataset', 'Classifier'] + [metric.__name__ for metric in metrics])\n",
        "\n",
        "# Evaluate each resampled dataset with each classifier\n",
        "for resampling_name, (X_res, y_res) in resampling_techniques.items():\n",
        "    for clf_name, clf in classifiers.items():\n",
        "        clf.fit(X_res, y_res)\n",
        "        predictions = clf.predict(X_test)\n",
        "        probabilities = clf.predict_proba(X_test)[:, 1]  # For ROC AUC\n",
        "\n",
        "        # Evaluate with each metric\n",
        "        precision = precision_score(y_test, predictions, zero_division=1)\n",
        "        recall = recall_score(y_test, predictions)\n",
        "        f1 = f1_score(y_test, predictions, zero_division=1)\n",
        "        roc_auc = roc_auc_score(y_test, probabilities)\n",
        "\n",
        "        # Append to results DataFrame\n",
        "        row = pd.DataFrame([[resampling_name, clf_name, precision, recall, f1, roc_auc]], columns=results.columns)\n",
        "        results = pd.concat([results, row], ignore_index=True)\n",
        "\n",
        "# Calculate an overall score for ranking (optional)\n",
        "results['Overall Score'] = results[[metric.__name__ for metric in metrics]].mean(axis=1)\n",
        "\n",
        "# Sort results for ranking\n",
        "ranked_results = results.sort_values(by='Overall Score', ascending=False)\n",
        "\n",
        "# Display the ranked table\n",
        "print(ranked_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c16742f9-bd8a-4828-fe90-6ae429d7aa7f",
        "id": "sv2iprbbuQ-G"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9)\n",
            "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
            "0            6      148             72             35        0  33.6   \n",
            "1            1       85             66             29        0  26.6   \n",
            "2            8      183             64              0        0  23.3   \n",
            "3            1       89             66             23       94  28.1   \n",
            "4            0      137             40             35      168  43.1   \n",
            "\n",
            "   DiabetesPedigreeFunction  Age  Outcome  \n",
            "0                     0.627   50        1  \n",
            "1                     0.351   31        0  \n",
            "2                     0.672   32        1  \n",
            "3                     0.167   21        0  \n",
            "4                     2.288   33        1  \n",
            "0\n",
            "             Dataset          Classifier  f1_score  precision_score  \\\n",
            "7  RandomOverSampler  LogisticRegression  0.666667         0.716049   \n",
            "5             ADASYN  LogisticRegression  0.637363         0.716049   \n",
            "3              SMOTE  LogisticRegression  0.636364         0.691358   \n",
            "2              SMOTE        RandomForest  0.684211         0.641975   \n",
            "4             ADASYN        RandomForest  0.635294         0.666667   \n",
            "0           Original        RandomForest  0.721311         0.543210   \n",
            "6  RandomOverSampler        RandomForest  0.638889         0.567901   \n",
            "1           Original  LogisticRegression  0.666667         0.518519   \n",
            "\n",
            "   recall_score  roc_auc_score  Overall Score  \n",
            "7      0.690476       0.836049       0.727310  \n",
            "5      0.674419       0.837284       0.716279  \n",
            "3      0.662722       0.839012       0.707364  \n",
            "2      0.662420       0.833045       0.705413  \n",
            "4      0.650602       0.826996       0.694890  \n",
            "0      0.619718       0.823909       0.677037  \n",
            "6      0.601307       0.832263       0.660090  \n",
            "1      0.583333       0.837531       0.651512  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
        "from urllib.request import urlopen\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "# Define the URL for the Breast Cancer Wisconsin (Original) Dataset\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
        "\n",
        "# Download and load the dataset into a pandas DataFrame\n",
        "column_names = ['ID', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape',\n",
        "                'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',\n",
        "                'Normal Nucleoli', 'Mitoses', 'Class']\n",
        "df = pd.read_csv(url, names=column_names)\n",
        "\n",
        "# Replace missing values denoted by '?' with NaN and then handle them\n",
        "df.replace('?', np.nan, inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "print(df.shape)\n",
        "df['Bare Nuclei'] = df['Bare Nuclei'].astype(int)\n",
        "\n",
        "# Drop the 'ID' column as it is not needed for the analysis\n",
        "df.drop('ID', axis=1, inplace=True)\n",
        "\n",
        "# Prepare the dataset for comparison\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# Convert the class labels to binary (2 -> 1 for benign, 4 -> 0 for malignant)\n",
        "y = y.map({2: 1, 4: 0})\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Define the resampling techniques\n",
        "resampling_techniques = {\n",
        "    'Original': (X_train, y_train),\n",
        "    'SMOTE': SMOTE(random_state=42).fit_resample(X_train, y_train),\n",
        "    'ADASYN': ADASYN(random_state=42).fit_resample(X_train, y_train),\n",
        "    'RandomOverSampler': RandomOverSampler(random_state=42).fit_resample(X_train, y_train)\n",
        "}\n",
        "\n",
        "# Define classifiers to test\n",
        "classifiers = {\n",
        "    'RandomForest': RandomForestClassifier(),\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000)\n",
        "}\n",
        "\n",
        "# Define metrics for evaluation\n",
        "metrics = [f1_score, precision_score, recall_score, roc_auc_score]\n",
        "\n",
        "# Store results\n",
        "results = pd.DataFrame(columns=['Dataset', 'Classifier'] + [metric.__name__ for metric in metrics])\n",
        "\n",
        "# Evaluate each resampled dataset with each classifier\n",
        "for resampling_name, (X_res, y_res) in resampling_techniques.items():\n",
        "    for clf_name, clf in classifiers.items():\n",
        "        clf.fit(X_res, y_res)\n",
        "        predictions = clf.predict(X_test)\n",
        "        probabilities = clf.predict_proba(X_test)[:, 1]  # For ROC AUC\n",
        "\n",
        "        # Evaluate with each metric\n",
        "        precision = precision_score(y_test, predictions, zero_division=1)\n",
        "        recall = recall_score(y_test, predictions)\n",
        "        f1 = f1_score(y_test, predictions, zero_division=1)\n",
        "        roc_auc = roc_auc_score(y_test, probabilities)\n",
        "\n",
        "        # Append to results DataFrame using pd.concat\n",
        "        row = pd.DataFrame([[resampling_name, clf_name, precision, recall, f1, roc_auc]], columns=results.columns)\n",
        "        results = pd.concat([results, row], ignore_index=True)\n",
        "\n",
        "# Calculate an overall score for ranking (optional)\n",
        "results['Overall Score'] = results[[metric.__name__ for metric in metrics]].mean(axis=1)\n",
        "\n",
        "# Sort results for ranking\n",
        "ranked_results = results.sort_values(by='Overall Score', ascending=False)\n",
        "\n",
        "# Display the ranked table\n",
        "print(ranked_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vJOyOrQ55fu",
        "outputId": "7561186f-dde6-4854-e203-91e664a9c6ae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(683, 11)\n",
            "             Dataset          Classifier  f1_score  precision_score  \\\n",
            "6  RandomOverSampler        RandomForest  1.000000         0.962406   \n",
            "4             ADASYN        RandomForest  1.000000         0.962406   \n",
            "0           Original        RandomForest  0.992248         0.962406   \n",
            "2              SMOTE        RandomForest  1.000000         0.954887   \n",
            "3              SMOTE  LogisticRegression  0.984615         0.962406   \n",
            "7  RandomOverSampler  LogisticRegression  0.984615         0.962406   \n",
            "1           Original  LogisticRegression  0.969925         0.969925   \n",
            "5             ADASYN  LogisticRegression  0.984496         0.954887   \n",
            "\n",
            "   recall_score  roc_auc_score  Overall Score  \n",
            "6      0.980843       0.992690       0.983985  \n",
            "4      0.980843       0.990393       0.983410  \n",
            "0      0.977099       0.992899       0.981163  \n",
            "2      0.976923       0.992011       0.980955  \n",
            "3      0.973384       0.994256       0.978665  \n",
            "7      0.973384       0.993839       0.978561  \n",
            "1      0.969925       0.995718       0.976373  \n",
            "5      0.969466       0.990184       0.974758  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
        "\n",
        "# Define the URL for the Census Income Dataset\n",
        "url_train = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
        "url_test = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test'\n",
        "\n",
        "# Define the column names\n",
        "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
        "                'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n",
        "                'hours-per-week', 'native-country', 'income']\n",
        "\n",
        "# Load the datasets into pandas DataFrames\n",
        "df_train = pd.read_csv(url_train, names=column_names, sep=',\\s', na_values='?', engine='python')\n",
        "df_test = pd.read_csv(url_test, names=column_names, sep=',\\s', na_values='?', skiprows=1, engine='python')\n",
        "\n",
        "# Concatenate train and test datasets\n",
        "df = pd.concat([df_train, df_test], ignore_index=True)\n",
        "print(df.shape)\n",
        "# Handle missing values by dropping rows with NaNs\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Convert categorical features to numerical using one-hot encoding\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Prepare the dataset for comparison\n",
        "X = df.drop('income_>50K', axis=1)\n",
        "y = df['income_>50K']\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Define the resampling techniques\n",
        "resampling_techniques = {\n",
        "    'Original': (X_train, y_train),\n",
        "    'SMOTE': SMOTE(random_state=42).fit_resample(X_train, y_train),\n",
        "    'ADASYN': ADASYN(random_state=42).fit_resample(X_train, y_train),\n",
        "    'RandomOverSampler': RandomOverSampler(random_state=42).fit_resample(X_train, y_train)\n",
        "}\n",
        "\n",
        "# Define classifiers to test\n",
        "classifiers = {\n",
        "    'RandomForest': RandomForestClassifier(),\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000)\n",
        "}\n",
        "\n",
        "# Define metrics for evaluation\n",
        "metrics = [f1_score, precision_score, recall_score, roc_auc_score]\n",
        "\n",
        "# Store results\n",
        "results = pd.DataFrame(columns=['Dataset', 'Classifier'] + [metric.__name__ for metric in metrics])\n",
        "\n",
        "# Evaluate each resampled dataset with each classifier\n",
        "for resampling_name, (X_res, y_res) in resampling_techniques.items():\n",
        "    for clf_name, clf in classifiers.items():\n",
        "        clf.fit(X_res, y_res)\n",
        "        predictions = clf.predict(X_test)\n",
        "        probabilities = clf.predict_proba(X_test)[:, 1]  # For ROC AUC\n",
        "\n",
        "        # Evaluate with each metric\n",
        "        precision = precision_score(y_test, predictions, zero_division=1)\n",
        "        recall = recall_score(y_test, predictions)\n",
        "        f1 = f1_score(y_test, predictions, zero_division=1)\n",
        "        roc_auc = roc_auc_score(y_test, probabilities)\n",
        "\n",
        "        # Append to results DataFrame using pd.concat\n",
        "        row = pd.DataFrame([[resampling_name, clf_name, precision, recall, f1, roc_auc]], columns=results.columns)\n",
        "        results = pd.concat([results, row], ignore_index=True)\n",
        "\n",
        "# Calculate an overall score for ranking (optional)\n",
        "results['Overall Score'] = results[[metric.__name__ for metric in metrics]].mean(axis=1)\n",
        "\n",
        "# Sort results for ranking\n",
        "ranked_results = results.sort_values(by='Overall Score', ascending=False)\n",
        "\n",
        "# Display the ranked table\n",
        "print(ranked_results)\n"
      ],
      "metadata": {
        "id": "RKQp7AZuAa4Y",
        "outputId": "5801b660-4687-4d9f-e617-19e40d1e1c68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48842, 15)\n",
            "             Dataset          Classifier  f1_score  precision_score  \\\n",
            "6  RandomOverSampler        RandomForest  0.684783         0.699378   \n",
            "2              SMOTE        RandomForest  0.699198         0.658526   \n",
            "0           Original        RandomForest  0.748359         0.607460   \n",
            "4             ADASYN        RandomForest  0.694234         0.652309   \n",
            "5             ADASYN  LogisticRegression  0.211982         0.714920   \n",
            "3              SMOTE  LogisticRegression  0.234683         0.602131   \n",
            "7  RandomOverSampler  LogisticRegression  0.403438         0.312611   \n",
            "1           Original  LogisticRegression  0.574074         0.027531   \n",
            "\n",
            "   recall_score  roc_auc_score  Overall Score  \n",
            "6      0.692004       0.936194       0.753090  \n",
            "2      0.678253       0.933637       0.742404  \n",
            "0      0.670588       0.936322       0.740682  \n",
            "4      0.672619       0.930858       0.737505  \n",
            "5      0.327003       0.654950       0.477214  \n",
            "3      0.337733       0.652642       0.456798  \n",
            "7      0.352264       0.611350       0.419916  \n",
            "1      0.052542       0.502051       0.289050  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
        "import requests\n",
        "from io import StringIO\n",
        "\n",
        "# Define the URLs for the Wine Quality Dataset\n",
        "url_red = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
        "url_white = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'\n",
        "\n",
        "# Download the datasets\n",
        "response_red = requests.get(url_red)\n",
        "response_white = requests.get(url_white)\n",
        "\n",
        "# Load the datasets into pandas DataFrames\n",
        "df_red = pd.read_csv(StringIO(response_red.text), sep=';')\n",
        "df_white = pd.read_csv(StringIO(response_white.text), sep=';')\n",
        "\n",
        "# Add a column to distinguish between red and white wine\n",
        "df_red['wine_type'] = 'red'\n",
        "df_white['wine_type'] = 'white'\n",
        "\n",
        "# Concatenate the datasets\n",
        "df = pd.concat([df_red, df_white], ignore_index=True)\n",
        "print(df.shape)\n",
        "# Check for NaN values and handle them if any\n",
        "print(df.isna().sum())\n",
        "\n",
        "# Assuming no NaN values for this dataset, if there were any, you would handle them like this:\n",
        "# df.dropna(inplace=True) or df.fillna(method='ffill', inplace=True)\n",
        "\n",
        "# Convert the wine quality into a binary classification problem\n",
        "# For simplicity, let's classify quality > 6 as \"good\" (1) and <= 6 as \"not good\" (0)\n",
        "df['quality'] = np.where(df['quality'] > 6, 1, 0)\n",
        "\n",
        "# Convert categorical feature 'wine_type' using one-hot encoding\n",
        "df = pd.get_dummies(df, columns=['wine_type'], drop_first=True)\n",
        "\n",
        "# Prepare the dataset for comparison\n",
        "X = df.drop('quality', axis=1)\n",
        "y = df['quality']\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Define the resampling techniques\n",
        "resampling_techniques = {\n",
        "    'Original': (X_train, y_train),\n",
        "    'SMOTE': SMOTE(random_state=42).fit_resample(X_train, y_train),\n",
        "    'ADASYN': ADASYN(random_state=42).fit_resample(X_train, y_train),\n",
        "    'RandomOverSampler': RandomOverSampler(random_state=42).fit_resample(X_train, y_train)\n",
        "}\n",
        "\n",
        "# Define classifiers to test\n",
        "classifiers = {\n",
        "    'RandomForest': RandomForestClassifier(),\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000)\n",
        "}\n",
        "\n",
        "# Define metrics for evaluation\n",
        "metrics = [f1_score, precision_score, recall_score, roc_auc_score]\n",
        "\n",
        "# Store results\n",
        "results = pd.DataFrame(columns=['Dataset', 'Classifier'] + [metric.__name__ for metric in metrics])\n",
        "\n",
        "# Evaluate each resampled dataset with each classifier\n",
        "for resampling_name, (X_res, y_res) in resampling_techniques.items():\n",
        "    for clf_name, clf in classifiers.items():\n",
        "        clf.fit(X_res, y_res)\n",
        "        predictions = clf.predict(X_test)\n",
        "        probabilities = clf.predict_proba(X_test)[:, 1]  # For ROC AUC\n",
        "\n",
        "        # Evaluate with each metric\n",
        "        precision = precision_score(y_test, predictions, zero_division=1)\n",
        "        recall = recall_score(y_test, predictions)\n",
        "        f1 = f1_score(y_test, predictions, zero_division=1)\n",
        "        roc_auc = roc_auc_score(y_test, probabilities)\n",
        "\n",
        "        # Append to results DataFrame using pd.concat\n",
        "        row = pd.DataFrame([[resampling_name, clf_name, precision, recall, f1, roc_auc]], columns=results.columns)\n",
        "        results = pd.concat([results, row], ignore_index=True)\n",
        "\n",
        "# Calculate an overall score for ranking (optional)\n",
        "results['Overall Score'] = results[[metric.__name__ for metric in metrics]].mean(axis=1)\n",
        "\n",
        "# Sort results for ranking\n",
        "ranked_results = results.sort_values(by='Overall Score', ascending=False)\n",
        "\n",
        "# Display the ranked table\n",
        "print(ranked_results)\n"
      ],
      "metadata": {
        "id": "nmat1K51OIeF",
        "outputId": "826a9fc3-ca73-41be-985f-dc600741fb1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6497, 13)\n",
            "fixed acidity           0\n",
            "volatile acidity        0\n",
            "citric acid             0\n",
            "residual sugar          0\n",
            "chlorides               0\n",
            "free sulfur dioxide     0\n",
            "total sulfur dioxide    0\n",
            "density                 0\n",
            "pH                      0\n",
            "sulphates               0\n",
            "alcohol                 0\n",
            "quality                 0\n",
            "wine_type               0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Dataset          Classifier  f1_score  precision_score  \\\n",
            "6  RandomOverSampler        RandomForest  0.751553         0.631854   \n",
            "2              SMOTE        RandomForest  0.648325         0.707572   \n",
            "4             ADASYN        RandomForest  0.639344         0.712794   \n",
            "0           Original        RandomForest  0.793358         0.561358   \n",
            "5             ADASYN  LogisticRegression  0.405063         0.751958   \n",
            "7  RandomOverSampler  LogisticRegression  0.391892         0.757180   \n",
            "3              SMOTE  LogisticRegression  0.395028         0.746736   \n",
            "1           Original  LogisticRegression  0.614865         0.237598   \n",
            "\n",
            "   recall_score  roc_auc_score  Overall Score  \n",
            "6      0.686525       0.915868       0.746450  \n",
            "2      0.676654       0.911709       0.736065  \n",
            "4      0.674074       0.911425       0.734409  \n",
            "0      0.657492       0.916557       0.732191  \n",
            "5      0.526508       0.806064       0.622398  \n",
            "7      0.516474       0.804049       0.617399  \n",
            "3      0.516712       0.805039       0.615879  \n",
            "1      0.342750       0.805079       0.500073  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Install necessary libraries\n",
        "!pip install pandas scikit-learn imbalanced-learn\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
        "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
        "\n",
        "# Load the dataset into a pandas DataFrame\n",
        "df = pd.read_csv('train.csv')\n",
        "print(df.shape)\n",
        "print(df.head())\n",
        "\n",
        "# Check for NaN values in the target variable\n",
        "print(df['target'].isna().sum())\n",
        "\n",
        "# Drop rows where target variable is NaN\n",
        "df = df.dropna(subset=['target'])\n",
        "\n",
        "# Prepare the dataset for comparison\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Define the resampling techniques\n",
        "resampling_techniques = {\n",
        "    'Original': (X_train, y_train),\n",
        "    'SMOTE': SMOTE(random_state=42).fit_resample(X_train, y_train),\n",
        "    'ADASYN': ADASYN(random_state=42).fit_resample(X_train, y_train),\n",
        "    'RandomOverSampler': RandomOverSampler(random_state=42).fit_resample(X_train, y_train)\n",
        "}\n",
        "\n",
        "# Define classifiers to test\n",
        "classifiers = {\n",
        "    'RandomForest': RandomForestClassifier(),\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000)\n",
        "}\n",
        "\n",
        "# Define metrics for evaluation\n",
        "metrics = [f1_score, precision_score, recall_score, roc_auc_score]\n",
        "\n",
        "# Store results\n",
        "results = pd.DataFrame(columns=['Dataset', 'Classifier'] + [metric.__name__ for metric in metrics])\n",
        "\n",
        "# Evaluate each resampled dataset with each classifier\n",
        "for resampling_name, (X_res, y_res) in resampling_techniques.items():\n",
        "    for clf_name, clf in classifiers.items():\n",
        "        clf.fit(X_res, y_res)\n",
        "        predictions = clf.predict(X_test)\n",
        "        probabilities = clf.predict_proba(X_test)[:, 1]  # For ROC AUC\n",
        "\n",
        "        # Evaluate with each metric\n",
        "        precision = precision_score(y_test, predictions, zero_division=1)\n",
        "        recall = recall_score(y_test, predictions)\n",
        "        f1 = f1_score(y_test, predictions, zero_division=1)\n",
        "        roc_auc = roc_auc_score(y_test, probabilities)\n",
        "\n",
        "        # Append to results DataFrame\n",
        "        row = pd.DataFrame([[resampling_name, clf_name, precision, recall, f1, roc_auc]], columns=results.columns)\n",
        "        results = pd.concat([results, row], ignore_index=True)\n",
        "\n",
        "# Calculate an overall score for ranking (optional)\n",
        "results['Overall Score'] = results[[metric.__name__ for metric in metrics]].mean(axis=1)\n",
        "\n",
        "# Sort results for ranking\n",
        "ranked_results = results.sort_values(by='Overall Score', ascending=False)\n",
        "\n",
        "# Display the ranked table\n",
        "print(ranked_results)\n"
      ],
      "metadata": {
        "id": "lY68-u2xDBC4",
        "outputId": "2f127fe2-5b82-4128-ce38-c4a4289edf49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "(595212, 59)\n",
            "   id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
            "0   7       0          2              2          5              1   \n",
            "1   9       0          1              1          7              0   \n",
            "2  13       0          5              4          9              1   \n",
            "3  16       0          0              1          2              0   \n",
            "4  17       0          0              2          0              1   \n",
            "\n",
            "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ...  \\\n",
            "0              0              0              1              0  ...   \n",
            "1              0              0              0              1  ...   \n",
            "2              0              0              0              1  ...   \n",
            "3              0              1              0              0  ...   \n",
            "4              0              1              0              0  ...   \n",
            "\n",
            "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
            "0           9           1           5           8               0   \n",
            "1           3           1           1           9               0   \n",
            "2           4           2           7           7               0   \n",
            "3           2           2           4           9               0   \n",
            "4           3           1           1           3               0   \n",
            "\n",
            "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
            "0               1               1               0               0   \n",
            "1               1               1               0               1   \n",
            "2               1               1               0               1   \n",
            "3               0               0               0               0   \n",
            "4               0               0               1               1   \n",
            "\n",
            "   ps_calc_20_bin  \n",
            "0               1  \n",
            "1               0  \n",
            "2               0  \n",
            "3               0  \n",
            "4               0  \n",
            "\n",
            "[5 rows x 59 columns]\n",
            "0\n",
            "             Dataset          Classifier  f1_score  precision_score  \\\n",
            "3              SMOTE  LogisticRegression  0.036446         1.000000   \n",
            "7  RandomOverSampler  LogisticRegression  0.036446         1.000000   \n",
            "1           Original  LogisticRegression  1.000000         0.000000   \n",
            "6  RandomOverSampler        RandomForest  0.600000         0.000461   \n",
            "5             ADASYN  LogisticRegression  0.039632         0.339889   \n",
            "0           Original        RandomForest  0.333333         0.000615   \n",
            "4             ADASYN        RandomForest  0.079646         0.001383   \n",
            "2              SMOTE        RandomForest  0.075630         0.001383   \n",
            "\n",
            "   recall_score  roc_auc_score  Overall Score  \n",
            "3      0.070329       0.496377       0.400788  \n",
            "7      0.070329       0.496377       0.400788  \n",
            "1      0.000000       0.493433       0.373358  \n",
            "6      0.000921       0.590947       0.298082  \n",
            "5      0.070986       0.516919       0.241856  \n",
            "0      0.001227       0.587201       0.230594  \n",
            "4      0.002719       0.578992       0.165685  \n",
            "2      0.002716       0.581056       0.165196  \n",
            "CPU times: user 20min 49s, sys: 6.49 s, total: 20min 56s\n",
            "Wall time: 20min 37s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head())\n",
        "\n",
        "# Check for NaN values in the target variable\n",
        "print(df['target'].isna().sum())\n",
        "\n",
        "# Drop rows where target variable is NaN\n",
        "df = df.dropna(subset=['target'])\n",
        "\n",
        "# Prepare the dataset for comparison\n",
        "X = df.drop(['id', 'target'], axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Define the resampling techniques\n",
        "resampling_techniques = {\n",
        "    'Original': (X_train, y_train),\n",
        "    'SMOTE': SMOTE(random_state=42).fit_resample(X_train, y_train),\n",
        "    'ADASYN': ADASYN(random_state=42).fit_resample(X_train, y_train),\n",
        "    'RandomOverSampler': RandomOverSampler(random_state=42).fit_resample(X_train, y_train)\n",
        "}\n",
        "\n",
        "# Define classifiers to test\n",
        "classifiers = {\n",
        "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42)\n",
        "}\n",
        "\n",
        "# Define metrics for evaluation\n",
        "metrics = [f1_score, precision_score, recall_score, roc_auc_score]\n",
        "\n",
        "# Store results\n",
        "results = pd.DataFrame(columns=['Dataset', 'Classifier'] + [metric.__name__ for metric in metrics])\n",
        "\n",
        "# Evaluate each resampled dataset with each classifier\n",
        "for resampling_name, (X_res, y_res) in resampling_techniques.items():\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    X_res = scaler.fit_transform(X_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    for clf_name, clf in classifiers.items():\n",
        "        clf.fit(X_res, y_res)\n",
        "        predictions = clf.predict(X_test_scaled)\n",
        "        probabilities = clf.predict_proba(X_test_scaled)[:, 1]  # For ROC AUC\n",
        "\n",
        "        # Evaluate with each metric\n",
        "        precision = precision_score(y_test, predictions, zero_division=1)\n",
        "        recall = recall_score(y_test, predictions)\n",
        "        f1 = f1_score(y_test, predictions, zero_division=1)\n",
        "        roc_auc = roc_auc_score(y_test, probabilities)\n",
        "\n",
        "        # Append to results DataFrame\n",
        "        row = pd.DataFrame([[resampling_name, clf_name, precision, recall, f1, roc_auc]], columns=results.columns)\n",
        "        results = pd.concat([results, row], ignore_index=True)\n",
        "\n",
        "# Calculate an overall score for ranking (optional)\n",
        "results['Overall Score'] = results[[metric.__name__ for metric in metrics]].mean(axis=1)\n",
        "\n",
        "# Sort results for ranking\n",
        "ranked_results = results.sort_values(by='Overall Score', ascending=False)\n",
        "\n",
        "# Display the ranked table\n",
        "print(ranked_results)\n"
      ],
      "metadata": {
        "id": "O84x-jl4UgxA",
        "outputId": "e699ee5d-3b63-4770-f8c4-eefdbf43b8b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
            "0   7       0          2              2          5              1   \n",
            "1   9       0          1              1          7              0   \n",
            "2  13       0          5              4          9              1   \n",
            "3  16       0          0              1          2              0   \n",
            "4  17       0          0              2          0              1   \n",
            "\n",
            "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ...  \\\n",
            "0              0              0              1              0  ...   \n",
            "1              0              0              0              1  ...   \n",
            "2              0              0              0              1  ...   \n",
            "3              0              1              0              0  ...   \n",
            "4              0              1              0              0  ...   \n",
            "\n",
            "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
            "0           9           1           5           8               0   \n",
            "1           3           1           1           9               0   \n",
            "2           4           2           7           7               0   \n",
            "3           2           2           4           9               0   \n",
            "4           3           1           1           3               0   \n",
            "\n",
            "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
            "0               1               1               0               0   \n",
            "1               1               1               0               1   \n",
            "2               1               1               0               1   \n",
            "3               0               0               0               0   \n",
            "4               0               0               1               1   \n",
            "\n",
            "   ps_calc_20_bin  \n",
            "0               1  \n",
            "1               0  \n",
            "2               0  \n",
            "3               0  \n",
            "4               0  \n",
            "\n",
            "[5 rows x 59 columns]\n",
            "0\n",
            "             Dataset          Classifier  f1_score  precision_score  \\\n",
            "1           Original  LogisticRegression  1.000000         0.000000   \n",
            "7  RandomOverSampler  LogisticRegression  0.052961         0.552858   \n",
            "6  RandomOverSampler        RandomForest  0.666667         0.000307   \n",
            "0           Original        RandomForest  0.333333         0.000615   \n",
            "3              SMOTE  LogisticRegression  0.045350         0.093577   \n",
            "5             ADASYN  LogisticRegression  0.045585         0.092502   \n",
            "4             ADASYN        RandomForest  0.064444         0.004456   \n",
            "2              SMOTE        RandomForest  0.063570         0.003995   \n",
            "\n",
            "   recall_score  roc_auc_score  Overall Score  \n",
            "1      0.000000       0.623378       0.405845  \n",
            "7      0.096662       0.624813       0.331824  \n",
            "6      0.000614       0.592247       0.314959  \n",
            "0      0.001227       0.589698       0.231218  \n",
            "3      0.061092       0.523506       0.180881  \n",
            "5      0.061073       0.522758       0.180480  \n",
            "4      0.008336       0.573735       0.162743  \n",
            "2      0.007518       0.575063       0.162536  \n",
            "CPU times: user 20min 56s, sys: 9.98 s, total: 21min 6s\n",
            "Wall time: 20min 36s\n"
          ]
        }
      ]
    }
  ]
}